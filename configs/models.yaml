# LLM Model Configurations
# Each model defines the parameters for LiteLLM calls

models:
  # OpenAI GPT-4o - Fast and capable
  gpt-4o:
    model_name: "gpt-4o"  # LiteLLM model identifier
    temperature: 0.7
    max_tokens: 4096
    description: "OpenAI GPT-4o - Fast, multimodal, and cost-effective"
    env_var: "OPENAI_API_KEY"

  # OpenAI GPT-4o-mini - Cheaper, faster
  gpt-4o-mini:
    model_name: "gpt-4o-mini"
    temperature: 0.7
    max_tokens: 4096
    description: "OpenAI GPT-4o-mini - Smaller, faster, cheaper variant"
    env_var: "OPENAI_API_KEY"

  # Anthropic Claude 3.5 Sonnet - Best for complex reasoning
  claude-3-5-sonnet:
    model_name: "claude-3-5-sonnet-20241022"
    temperature: 0.7
    max_tokens: 4096
    description: "Anthropic Claude 3.5 Sonnet - Excellent for coding and reasoning"
    env_var: "ANTHROPIC_API_KEY"

  # Free model via OpenRouter for testing
  openrouter-free:
    model_name: "openrouter/google/gemini-2.0-flash-exp:free"
    temperature: 0.7
    max_tokens: 4096
    description: "Free model via OpenRouter for testing"
    env_var: "OPENROUTER_API_KEY"

# Default model to use if not specified
default_model: "gpt-4o-mini"
